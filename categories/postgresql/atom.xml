<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: postgresql | David Cramer's Blog]]></title>
  <link href="http://dcramer.github.com/categories/postgresql/atom.xml" rel="self"/>
  <link href="http://dcramer.github.com/"/>
  <updated>2012-04-24T22:26:09-07:00</updated>
  <id>http://dcramer.github.com/</id>
  <author>
    <name><![CDATA[David Cramer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Sticking With Standards]]></title>
    <link href="http://dcramer.github.com/2012/04/24/sticking-with-standards"/>
    <updated>2012-04-24T22:23:00-07:00</updated>
    <id>http://dcramer.github.com/2012/04/24/sticking-with-standards</id>
    <content type="html"><![CDATA[<p>More and more I'm seeing the "requirements.txt pattern" come up. This generally refers to projects (but not just), and
seems to have started around the same time as Heroku adopting Python. I feel like this is something that matters in the
Python world, and because I have an opinion on everything, I want to share mine.</p>




<h3>requirements.txt</h3>




<p>Let's first talk about what this pattern actually is. As you should already be familiar with pip (if you're not, this
post is not for you), the idea of this is that whatever your'e doing, is installable by pointing pip at a requirements.txt
file which contains a list of your projects dependencies. This has some obvious benefits, one being that you can
mark repositories as dependencies.</p>




<p>Another benefit of this is when have a large project (like DISQUS) and your dependencies can vary between environments. For
example, we have several various requirements files for disqus-web (our largest package):</p>




<pre>
requirements/global.txt
requirements/production.txt
requirements/development.txt
</pre>




<p>These end up being pretty obvious, and when an app has specific needs there's no reason not to approach the problem this
way. That said, you dont <strong>need</strong> to do things this way, and in every project other than our main repository,
including our open source work, all dependencies are specified completely in setup.py. Even in this case, we could just
as easily specify our core requirements as part of the package and simple have additional files which label the production
and development dependencies.</p>




<h3>setup.py is the right choice</h3>




<p>A common argument for not using setup.py is that a library is not the same as an app (or larger project). Why not? We
employ the same metadata in everything. Each contains a list of dependencies, some various metadata, and possibly a list
of extra resources (such as scripts, or documentation). Fundamentally they're identical. Additionally, if pip is your
thing, it <strong>does not prevent you from using setup.py</strong>. Let's take an example setup.py:</p>


<p>{% codeblock lang:python %}
from setuptools import setup, find_packages</p>

<h1>Clever hack to avoid requiring Nose</h1>

<p>if 'nosetests' == sys.argv[1]:</p>

<pre><code>setup_requires = ['nose&gt;=1.0']
</code></pre>

<p>else:</p>

<pre><code>setup_requires = []
</code></pre>

<p>tests_require = [</p>

<pre><code>'nose&gt;=1.0',
'unittest2==0.5.1',
</code></pre>

<p>]</p>

<p>requires = [</p>

<pre><code>'Flask==0.8',
'redis==2.4.11',
'hiredis==0.1.1',
'nydus==0.8.1',
</code></pre>

<p>]</p>

<p>setup(</p>

<pre><code>name='something-sexy',
version='1.0.0',
author="DISQUS",
author_email="dev@disqus.com",
package_dir={'': 'src'},
packages=find_packages("src"),
install_requires=requires,
tests_require=tests_require,
setup_requires=setup_requires,
zip_safe=False,
</code></pre>

<p>)
{% endcodeblock %}</p>

<p>Now, in our case, this is probably a service on Disqus, which means we're not listing it as a dependancy. In every
single scenario we have, we want our package to be on <code>PYTHONPATH</code>, and this is no different. Usually this
is done with setuptools, and the (albeit, somewhat broken) <code>develop</code> command. Even if you want to use pip,
that's not a problem:</p>




<pre>
pip install -e .
</pre>




<p>What's even more important is that you <strong>stick with standards</strong>, especially in our growing ecosystem of
open source and widely available libraries. There's absolutely no reason to have to explain to a developer that they
need to run some arbitrary command to get your neat tool to install. Following the well defined and adopted standards
ensures that is never the case.</p>




<p>Keep it simple. Keep it obvious.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Arrays as Materialized Paths in Postgres]]></title>
    <link href="http://dcramer.github.com/2012/04/08/using-arrays-as-materialized-paths-in-postgres"/>
    <updated>2012-04-08T16:52:00-07:00</updated>
    <id>http://dcramer.github.com/2012/04/08/using-arrays-as-materialized-paths-in-postgres</id>
    <content type="html"><![CDATA[<p>Something we've been casually working on at Disqus for <a href="http://justcramer.com/2010/05/30/scaling-threaded-comments-on-django-at-disqus/">quite some time</a> is an improved pagination method for threaded comments. This is obviously pretty important to us, it drives the very foundation of our product. It also happens to be an area that's somewhat challenging, and has a <a href="http://en.wikipedia.org/wiki/Nested_intervals">wide</a> <a href="http://en.wikipedia.org/wiki/Nested_set_model">array</a> <a href="http://en.wikipedia.org/wiki/Adjacency_list">of</a> <a href="https://communities.bmc.com/communities/docs/DOC-9902">solutions</a>. In the end, this is an overly complicated solution to solve the problem of threads having 10s or 100s of thousands of comments.</p>




<p>For some background, our first implementation is very similar to how <a href="http://reddit.com">Reddit</a> and many other systems work. It generally looks something like this:</p>




<ol>
    <li>Fetch all children for a tree</li>
    <li>Resort them in memory</li>
    <li>Return the N entry result set</li>
</ol>




<p>While fairly easy to implement, this has the enormous cost of pulling down every single child and resorting it at an application level. There are various ways to optimize this, and we even attempted doing it <a href="http://justcramer.com/2010/05/30/scaling-threaded-comments-on-django-at-disqus/">within the database</a> itself. In the end, none of our solutions worked at scale. They would either be too write heavy, or they'd move too much of the logic (read: CPU usage) to the database servers. That said, they led to something great, and in the end we settled on a solution that's neither too write or read heavy. That solution was materialized paths, but not in your typical way.</p>




<p>A materialized path generally is represented as a serialization of all parents. So in a simple case, it might be a simple delimited list of id values. As an example, let's say that we have a list of comments that are guaranteed to only be less than 1000 for their identifying value:</p>




<pre>
001
001002
001002003
001002007
001004
001005
001005006
</pre>




<p>In this case we've managed to stuff all of this into a sortable numeric value. Unfortunately, in the real world, it's never this easy, so we looked for existing solutions to solve this problem. We'll skip all of the bikeshedding here, and jump straight to our solution: Arrays.</p>




<p>Arrays are quite an interesting feature in Postgresql. They're a native data type, indexable, sortable, and contain a variety of operators and functions (and even more so in 8.4+). They also fit in nicely with our previous solution, with the caveat that we had to write to the arrays rather than generate them at execution time. In fact, they fit so well that we were able to directly translate a majority of the effort we spent while toying with CTEs.</p>




<p>What we finally settled on was a schema which looks something like this:</p>




<pre>
\d postsort

  Column   |   Type    | Modifiers 
-----------+-----------+-----------
 tree_id   | integer   | not null
 child_id  | integer   | not null
 value     | numeric[] | not null

Indexes:
    "postsort_pkey" PRIMARY KEY, btree (tree_id, child_id)
    "postsort_path" btree (tree_id, value)
</pre>




<p>A simple three-column schema gives us:</p>




<ul>
    <li><code>tree_id</code> The root node for this tree (for us, this is a comment thread)</li>
    <li><code>child_id</code> A child contained within this tree. There's a row for every child</li>
    <li><code>value</code> Our materialized path, implemented as an array</li>
</ul>




<p>The most important bit here is the <code>value</code>, and even more so what that array contains. Let's take a look at our previous example of simple numeric IDs, and how that'd be represented in this table:</p>




<pre>
child_id | value
----------------
1        | [1.0]
2        | [1.0, 2.0]
3        | [1.0, 2.0, 3.0]
7        | [1.0, 2.0, 7.0]
4        | [1.0, 4.0]
5        | [1.0, 5.0]
6        | [1.0, 5.0, 6.0]
</pre>




<p>You'll notice that the value always contains the id of the child as the last element, and is prefixed parents value. The child's ID <strong>must</strong> be present in order to guarantee sortability in conditions where these values are not unique. More specifically, in a real world scenario, you'll probably have some kind of <code>score</code> that you'd be including. As a demonstration of this eventual conflict, take the following values:</p>




<pre>
child_id | value
----------------
1        | [0.9134834, 1.0]
2        | [0.9134834, 1.0, 0.149341, 2.0]
3        | [0.9134834, 1.0, 0.149341, 2.0, 0.14123434, 3.0]
4        | [0.9134834, 1.0, 0.149341, 2.0, 0.14123434, 7.0]
5        | [0.9134834, 1.0, 0.149341, 5.0]
6        | [0.9134834, 1.0, 0.149341, 5.0, 0.601343, 5.0]
</pre>




<p>You'll see that we had a conflicting score for two children. If we always include the <strong>unique identifying numeric value</strong> we'll never have to worry about rows shifting into parents which they're not a part of. You will also see that we've prefixed each child's value with the score. This again gives us the numeric sorting order which we're looking for and allows us to sort by any arbitrary score. This could be anything from a timestamp to a completely custom scoring algorithm based on something like up and down votes on a child.</p>




<p>The schema and data storage is pretty straightforward, the bigger challenge is actually implementing the logic in your application (or if you're insane, within SQL triggers). We end up with a mess of SQL statements, with a singular goal to bring everything down to an atomic, transactionless nature. As an example, creating a new child probably resemebles something like the following:</p>


<p>{% codeblock lang:sql %}
INSERT INTO postsort (</p>

<pre><code>tree_id,
child_id,
value
</code></pre>

<p>)
SELECT t2.tree_id,</p>

<pre><code>   %(child_id)d as child_id,
   (t2.value || %(value)s::numeric[]) as value
</code></pre>

<p>FROM postsort as t2
WHERE t2.tree_id = %(tree_id)d
  AND t2.child_id = %(parent_child_id)d
{% endcodeblock %}</p>

<p>Once you've populated the table, queries become amazingly simple:</p>


<p>{% codeblock lang:sql %}
SELECT child_id
FROM postsort
WHERE tree_id = %(tree_id)s
ORDER BY value
{% endcodeblock %}</p>

<p>What's even more cool, aside from a lot of custom SQL we had to create for this to work in Django, is the fact that we were able to easily prototype and implement arrays within the Django ORM:</p>


<p>{% codeblock lang:python %}
class NumericArrayField(models.Field):</p>

<pre><code>__metaclass__ = models.SubfieldBase

def db_type(self):
    return "numeric[]"

def get_prep_value(self, value):
    if value:
        value = map(float, value)
    return value

def to_python(self, value):
    if value:
        value = map(float, value)
    return value
</code></pre>

<p>{% endcodeblock %}</p>

<p>We've just begun rolling this out at Disqus, but our initial performance and capacity tests are showing great results. The flexibility of arrays has been amazingly helpful in this scenario, and has pushed us into a new direction in what we can do with SQL. Disqus reaches more than 700 million unique visitors across its platform, and as always, Postgres has stood its ground and will continue to be our primary datastore of choice.</p>




<p>If Disqus sounds interesting to you, and you think you're a good fit and we're looking for passionate people to <a href="http://disqus.com/jobs/">join our team</a>.</p>

]]></content>
  </entry>
  
</feed>
