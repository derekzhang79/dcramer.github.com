<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: sentry | David Cramer's Blog]]></title>
  <link href="http://justcramer.com/categories/sentry/atom.xml" rel="self"/>
  <link href="http://justcramer.com/"/>
  <updated>2012-08-30T22:29:48-07:00</updated>
  <id>http://justcramer.com/</id>
  <author>
    <name><![CDATA[David Cramer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Moving Sentry from Heroku to Hardware]]></title>
    <link href="http://justcramer.com/2012/08/30/how-noops-works-for-sentry"/>
    <updated>2012-08-30T20:59:00-07:00</updated>
    <id>http://justcramer.com/2012/08/30/how-noops-works-for-sentry</id>
    <content type="html"><![CDATA[<p>I've talked a lot about how I run <a href="http://getsentry.com">getsentry.com</a>, mostly with <a href="http://justcramer.com/2012/06/02/the-cloud-is-not-for-you/">my experiences
on Heroku</a> and how I <a href="http://justcramer.com/2012/06/03/scaling-your-clouds/">switched to leased servers</a>. Many people consistently
suggested that operations work is difficult so they shouldn't deal with it themselves. I'm not going to tell you that my
roommate, <a href="http://twitter.com/drunkdev">Mike Clarke</a>, one of the few operations people we have at
<a href="http://disqus.com">DISQUS</a>, has it easy, but I'd like to give you a little bit of food for thought.</p>




<p>GetSentry started around Christmas of 2011. I had already built and open sourced <a href="http://github.com/getsentry/sentry">Sentry</a> at Disqus, and the idea was to
    take that work and create a Heroku AddOn out of it. The pitch was that I could make a little bit of money on the side
    simply by hosting Sentry for people. About three months later I had that prototype hosting service running on Heroku,
    accepting payments both via the AddOn infrastructure, as well as on my own using the amazing
    <a href="http://stripe.com">Stripe</a> platform.</p>




<p>Let's fast forward to today. I no longer run any servers on Heroku (or any cloud provider, other than S3 for backups),
    and instead I lease servers. Now the company I lease from is what most people would call a "budget provider". They're extremely cheap (they dont'
    add extreme margins to the cost of the machines you're leasing), and they do absolutely nothing for you. It's not
    for the faint of heart. That said, it's also how I can get away with very low costs.</p>




<p>I'm going to tell you a bit of a story of how I switched from Heroku to fully configured leased servers in less than
    a week, in my free time. I'm also going to try to convince you that it's really <strong>not that complicated</strong>,.</p>




<h3>The First Server</h3>




<p>This part could be more appropriately titled "Learning Chef". I'm fortunate to have some awesome coworkers, and even
    more fortunate that when I was making this transitiong I had access to my roommate to prod him about questions. I'm
    also extremely fortunate that medians like Google, IRC, and Twitter exist for any other questions I ever have.

<p>The first task I had to getting my prototype web server online was to get it all configured. I could have taken the
    old fashioned approach of creating a few config files locally (vcs maybe) and then sending them up to the server,
    as well as manually installing whatever packages I needed (nginx, memcache, etc.), but with Puppet and Chef becoming
    all the range I figured it was as good as time as ever to dig into one.</p>

<p>I decided to use the Chef hosted service, and after a few bumps with figuring out what all this Ruby stuff was about,
    I had managed to get a basic understanding of roles and cookbooks. After quite a bit of fiddling I had created a
    cookbook specific to getsentry (which holds things like setting up varoius paths), and a bunch of generic ones,
    like apt, nginx, memcached, python, etc.</p>

<h3>Creating a Recipe</h3>

<p>The meat of this was handled via Chef's awesome roles, and wiring up a few things in the 'default' recipe of getsentry:</p>

<pre>include_recipe "python"

directory "/srv/www" do
  owner "root"
  group "root"
  mode "0755"
  action :create
end

directory "/srv/www/getsentry.com" do
  owner "dcramer"
  group "dcramer"
  mode "0755"
  action :create
end
</pre>

<p>This formed the basis of any server that I would be running, and simply setup a couple of directories. I also simply
    gave ownership to my user, as I'm the only one working on the project, and didn't need the added complexities of build
    or system users.</p>

<p>I then moved on to a second recipe, which formed the basis of a web node. This one has a lot more to it, as it needed
    to configure nginx and memcache at the start:</p>

<pre>include_recipe "getsentry"
include_recipe "supervisor"

template "#{node[:nginx][:dir]}/sites-available/getsentry.com" do
  source "nginx/getsentry.erb"
  owner "root"
  group "root"
  mode 0644
  notifies :reload, "service[nginx]"
end

nginx_site "getsentry.com"

supervisor_service "web-1" do
  directory "/srv/www/getsentry.com/current/"
  command "/srv/www/getsentry.com/env/bin/python manage.py run_gunicorn -b 0.0.0.0:9000 -w #{node[:getsentry][:web][:workers]}"
  environment "DJANGO_CONF" => node[:django_conf]
  user "dcramer"
end

supervisor_service "web-2" do
  directory "/srv/www/getsentry.com/current/"
  command "/srv/www/getsentry.com/env/bin/python manage.py run_gunicorn -b 0.0.0.0:9001 -w #{node[:getsentry][:web][:workers]}"
  environment "DJANGO_CONF" => node[:django_conf]
  user "dcramer"
end</pre>

<p>There is a bit more to it then what I've shown, but all in all it was pretty simple. It just took me a bit to understand
    how chef functioned. All in all, I'm now an engineer that has experience in Chef, even if it's very little. From
    from my perspective (on the hiring end at Disqus), that's is an awesome addition to an engineer's skillset.</p>

<p>Once the web server was online, all I had to do was to configure a primary database server. I simply brought up another
    node, gave it a new role (db), and didn't even need to create a custom recipe (I simply reused the existing pgbouncer,
    postgersql, and redis recipes available elsewhere on the internet).</p>

<h3>Operational Complexity</h3>

<p>I stated in the beginning that I completed this process in less than a week. From Heroku to hardware it took me about
    three evenings of toying with Chef (mostly more complex components, like iptables and building a deploy script). What
    I really want to point out is how I have <strong>never</strong> been in an operations position. I've definitely configured
    servers (ala apt-get install nano), and know my way around, especially with a database, but most of this was fairly
    new to me.</p>

<p>The continued argument of it being "too difficult" to run your own servers is quite the overstatement, but it's not
    something you should ignore. There are many things I have to be concerned about, most importantly data loss and the
    ability to recover in the event of a disaster on my machines. These also aren't overly complex challenges to handle.</p>

<p>Data redundancy is handled a simple cron script that does nightly backups to S3. It's literally just a script that calls
    pg_dump and s3cmd to send the files upstream. Now that's not enough for any real requirements, so step two is simply
    setting up replication on your database node to a second server, if if that server is your application server.</p>

<p>Availability is the second big problem, and is easily avoided the same way that you avoid losing your database: have
    a second server. This again can be a server thats primary task is for something other than your application (it can
    be your database). It doesnt have to a permanent location for it. It only has to survive until a primary server is
    available or you're willing and able to invest in more hardware.</p>

<h3>Closing Thoughts</h3>

<p>I spent an initial three evenings, and another week's worth since on server configuring an operations. There were
    various problems like Postgres not being tuned well enough (pgtune is amazing by the way), DNS being slow (fuck it,
    use IPs), and some more minor things that needed addressed throughout that time. All in all, there's basically
    zero day-to-day operations concerns, and most of the work happens when I need to expand the system (which is rare).</p>

<p>All of it ended as an extremely valuable learning experience, but you using Chef wasn't a necessity. I could have done
    things the more "amateur" way, but I also now have the benefit of being able to bring online a server, run a few
    commands, and have a machine or even a cluster identical to what's already running.</p>

<p>On the limited hardware I run for getsentry.com, that is, two servers that actually service requests (one database,
    one app), we've serviced around 25 million requests since August 1st, doing anywhere from 500k to 2 million in a
    single day. That isn't that much traffic, but what's important is it services those requests very quickly, and is
    using very little of the resources that are dedicated to it. In the end, this means that Sentry's revenue will grow
    much more quickly than it's monthly bill will.</p>

<p>GetSentry has been profitable since its 4th month, and currently only spends 10% of its monthly revenue (hardware and
    other third party services). That gap gets larger every month, and I've been more than happy to invest some of my
    time to keep that gap as large as possible. The irony of it all? I'm selling a service that's entirely open source,
    yet suggesting that you run your own hardware. For some people sacrificing cost for convenience is acceptable, for other
    it may not be.</p>

<p>Also, <a href="http://whoownsmyavailability.com/">this</a>.</p>

<p>Look for a future post with many more details on how I setup Chef (likely incorrect) with more in-depth code and
    configuration from the cookbooks.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scaling Your Clouds]]></title>
    <link href="http://justcramer.com/2012/06/03/scaling-your-clouds"/>
    <updated>2012-06-03T17:53:00-07:00</updated>
    <id>http://justcramer.com/2012/06/03/scaling-your-clouds</id>
    <content type="html"><![CDATA[<p>My <a href="http://justcramer.com/2012/06/02/the-cloud-is-not-for-you/">post</a> yesterday seems to have gotten all the cloud fanboy's panties into a twist, so I figured I'd give them something
else to rage about.</p>




<p>There were lots of claims that without the cloud you can't scale, or you dont have redundancy, or you can't come up
with the result of <em>2 + 2</em>. I can't even explain the level of ignorance I've seen come out of the woodwork.

<p>So let's clarify some things.</p>

<h3>"The Cloud"</h3>

<p>There are many definitions that float around for "the cloud", and what it means, and more specifically what it's
supposed to do for you. When I talk about it, I'm not talking about you setting up hundreds of your own servers and
virtualizing them. <strong>We do that too.</strong> I'm talking about the notion that there's some mythical provider
that is going to cater to your needs and you're never going to have to worry about operational concerns.</p>

<p>There is nothing wrong with using Heroku, AWS, Dotcloud, or any of the hundreds of other cloud providers out there.
They all provide you with some level of relaxed operational requirements. That said, you're still restricted to whatever
completely fucking shit hardware they decide is right for virtualization. Now I'm not talking AWS so much, as they do
allow reasonable size instances, but you're still restricted to what they're willing to offer. You never
have the option to order custom hardware.</p>

<h3>Scale</h3>

<p>A bunch of the internet hipsters on Hacker News and elsewhere seem to think that if you use the cloud, your application
is going to magically scale by adding more servers to it. That may be true if you're using MongoDB, but we dont
live in a fairy tale here and it will not ever work. There are very few systems that I'm aware
of that can scale from one machine to tens to hundreds to thousands without a massive rearchitecture of how you use the
system.</p>

<p>One of the first things I pointed out in my article was the fact that I had to spin up large amounts of instances to
handle temporary workload. Too bad the database was bottlenecking on concurrent writes to the same row. You can't ignore one important factor:
I cant just "spin up more database". There are many amazing systems out there that are built
on the notion of distributed data with the goal of some level of horizontal scalability (<a href="http://basho.com/products/riak-overview/">Riak</a>,
<a href="http://cassandra.apache.org/">Cassandra</a>). Even they also do not allow you to spin up more servers and gain more capacity immediately.</p>

<h3>Operations Complexity</h3>

<p>Another argument that was brought up was the fact that I now personally have to deal with redundancy, monitoring, security
fixes, OS upgrades, bringing up more servers, etc.. Sure, that's true. Except that that will cost me far less time than I would
have spent trying to create a SQL database that can horizontal scale to infinity.</p>

<ul>
    <li>Redundancy is easy, especially at small scale. Cloud hosting is not going to solve your database redundancy for you.</li>
    <li>Just because I'm hosting my own machines doesnt mean I cant use New Relic, or in my case <a href="http://scoutapp.com">Scout</a>.</li>
    <li>I dont need to frequently bring up additional servers to handle the load because my actual hardware performs 2000 times better than my old virtualized hardware</li>
    <li>Security updates? OS reloads? Its not like I'm compiling shit by hand, and through the convenience of configuration management this is unbelievably easy.</li>
</ul>

<p>If you ignore the entirety of operations, you will never have any idea what's going on when there's a problem.</p>

<h3>The Time/Cost Tradeoff</h3>

<p>In my original post I stated it took me about three days to get everything into Chef, and have the new hardware ordered and online. Even if this was three full days of my time, I had just spent four days a previous week trying to get the infinitely scalable cloud solution to perform well enough. Simple math right, four is more than three. <strong>Not worth it.</strong></p>

<p>I built <a href="https://www.getsentry.com">getsentry.com</a> specifically with the goal of optimizing cost vs
profit margins. Ths is the first month that it's been profitable, and unless every single customer jumps ship at once,
it's unlikely that I will ever have to put my own money (excluding my time) into the project again.</p>

<h3>tl;dr</h3>

<p>Virtualized computing has many great uses, but you do not <strong>need</strong> it, especially if you're just starting
a business. If you want to try out a provider, don't let me stop you. Make your own decisions. That said, you can be <em>anything</em>
at <em>any random company</em> and tell me you use the cloud successfully, and I'll give you a pat on the back. I'll then
tell you that we rent servers successfully, and by we, I mean <a href="http://disqus.com">DISQUS</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Cloud is Not For You]]></title>
    <link href="http://justcramer.com/2012/06/02/the-cloud-is-not-for-you"/>
    <updated>2012-06-02T13:57:00-07:00</updated>
    <id>http://justcramer.com/2012/06/02/the-cloud-is-not-for-you</id>
    <content type="html"><![CDATA[<p><strong>Update:</strong> Did I hurt your feelings with this post? Read
<a href="http://justcramer.com/2012/06/03/scaling-your-clouds/">Scaling your Clouds</a> so you can rage even more.</p>




<p>Well, maybe not specifically <em>you</em>, but the mass that screams it will solve their problems.</p>




<p>It's been a fun year so far. There's been exciting things happening both for me personally, as well as at DISQUS. One of
those things has been launching a new side project, <a href="https://www.getsentry.com">getsentry.com</a>. This is about
it's 4th month running publicly, and it's been doing very well. I wanted to talk a little bit about where it started, and
how quickly it's shifted in the stance of where it's going.</p>




<p>Around Christmas of 2011, and after a lot of prodding by <a href="http://www.craigkerstiens.com/">Craig Kerstiens</a> (of Heroku)
I had finally given in to the pressure of creating a hosted version of Sentry to launch as a Heroku addon. I already knew
Sentry was awesome, as did many others, and this just meant getting something I put a lot of effort into out in front of
so many others. It was very little work to get things up and running on Heroku, and just as easy to setup the addon
endpoints. We started a private beta shortly thereafter, and immediately picked up a bunch of the Django/Python crowd.</p>




<p>From there it slowly, but steadily grew in both customers and data. In fact, for the first couple of months we were able
to survive on just a few dynos and the first tier of dedicated postgres (which was the $200 package at the time). We've
also expanded to cover nearly all popular languages, including PHP, Ruby, Java, and even JavaScript.</p>




<p>A bit further in the background of how I structured the Sentry service:</p>




<ul>
    <li>Two separate apps (www and app)</li>
    <li>SSL everywhere (two certs, two addons, $40/month plus SSL cert costs)</li>
    <li>A minimum of two dynos each ($72/month~)</li>
    <li>Tier-1 dedicated DB (Ronin, $200/month)</li>
</ul>




<p>Now, before I continue, let me say that I thoroughly enjoyed using Heroku. It's a great service, I'm friends with a lot
of people there. That said, I want to explain why you shouldn't use Heroku, or the cloud. Let me also clarify that I'm not
talking about the limitations of the idea of the cloud, but more specifically the limitations I've seen from providers,
and specifically my experience with Heroku.</p>




<p>Right from the get-go we had a system that had pretty good HA and redundancy, especially due to how Heroku's Postgres
solution works. Unfortunately, we quickly saw the limitations of what both the Postgres and the dynos could handle.</p>




<p>Our first attempt to address this was to add worker nodes (ala Celery) to handle concurrency better. This turned into one
or two additional dynos dedicated to processing jobs, as well as an additional Redis addon. Unfortunately the Redis addon
is completely overpriced, we quickly shifted to pulling up a VM in Linode's eastcoast datacenter instead. This bought us
a little bit of time, but really I'd say we were only given an additional 10% capacity by what should have been a large
optimization.</p>




<p>Another week or two went by, and it was suggested that we get off the Ronin database, and upgrade to the Fugu package (
which bumped up the database cost to $400/month). This did quite a bit. In fact, this let us handle most things without
too much of a concern. A little while down the road, we had a customer sign up who was actually send realistic amounts of
data. More specifically, <strong>not even close to the amount of data Disqus' Sentry server handles</strong>, but about 10x
more than the rest of our customers combined had been sending.</p>




<p>Then shit started to hit the fan.</p>




<p>In no specific order, we started finding numerous problems with various systems:</p>




<ul>
    <li>Redis takes too much memory to reliably queue Sentry jobs.</li>
    <li>Dynos are either memory or CPU bound, but we have no idea how or why.</li>
    <li>The Postgres server can't handle any reasonable level of concurrency.</li>
    <li>We randomly have to spin up 20 dynos to get anywhere in the queue backlog.</li>
</ul>




<p>Given all of that, I made the decision that I was going to go back to using real hardware and managing it myself. I'm
no stranger to operations work, though it's never been my day job. I did however want to do this right, and with the advice
of my coworker, friend, and roommate, <a href="https://twitter.com/#!/sugarc0de">Mike Clarke</a> I decided I'd set these
up properly, with Chef.</p>




<p>About three days into it, and I had learned how to use Chef (I don't write Ruby), brought up two full pluggable
configurations for a db node and a web node, written a deployment script in Fabric, migrated to the new hardware and
destroyed my Heroku and Linode instances. Three days, that's all it took to replace the cloud.</p>




<p>Now you might argue that the cloud let's you scale up easily. <strong>YOU ARE WRONG, IT DOES NOT.</strong> The cloud
gives you the convenience, or more importantly, the illusion of convenience, that you can bring up nodes to add to your
network without giving it much thought. You can do that. You don't ever realistically need to do that.</p>




<p>Almost any company worth a damn can bring online a server within 24 hours, even budget companies. When have you actually
needed turnaround time faster than that? If you did, maybe you should read up on capacity planning.</p>




<p>The hosted Sentry now runs on two budget servers, one of which runs Postgres, pgbouncer, and Redis, the other handles
Nginx, Celery, memcached, and the Python webserver. The cost for these two machines? About $300/month. When I destroyed
Heroku, my bill was looking to be around $600-700 between Heroku and Linode. Given the numbers we run at Disqus, the
physical hardware should be able to handle no less than 2000% the capacity I was struggling to handle on the cloud.</p>




<p>I'm not saying you can't make use of the cloud. For example, Disqus uses Amazon for running large amounts of map/reduce
work. You know, <strong>elastic computing</strong>, the kind of computing that is inconsistent, unplanned, or generally
infrequent. I'm also not saying you shouldn't use Heroku. You should see if it works for you. However, if you ever come up
to me and argue that the cloud is going to fix any problem, I'll make the assumption that you're one of those annoying
kids that runs around screaming MongoDB and Node.js are the answer to all of the worlds problems.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Error Tracing in Sentry]]></title>
    <link href="http://justcramer.com/2011/01/25/error-tracing-in-sentry"/>
    <updated>2011-01-25T00:00:00-08:00</updated>
    <id>http://justcramer.com/2011/01/25/error-tracing-in-sentry</id>
    <content type="html"><![CDATA[<p>A few weeks ago we pushed out an update to <a href="http://github.com/dcramer/django-sentry">Sentry</a>, bumping it's version to 1.6.0. Among the changes was a new "Sentry ID" value which is created by the client, rather than relying on the server. This seems like something insignificant, but it allows you to do something very powerful: trace errors from the customer or developer down to the precise request and log entry.</p>




<h4>Exposing Sentry ID</h4>




<p>The new IDs are generated automatically when a message is processed (by the client), so you won't need to make any changes on that end. Likely, however, you're going to want to expose these at your application level for a couple of different reasons. The first one we're going to cover is your customer's experience.</p>




<p>The easiest way to expose this information in a useful manner, is by <strong>creating a modified 500.html</strong>. In DISQUS' case, we mention the error reference ID to the end-user, so that when they're reporting a problem they can pass along this information.</p>




<h5>Create a custom 500 handler</h5>




<p>The first thing you're going to need to do is to create a custom 500 handler. This defined in <code>urls.py</code>, so we're just going to go ahead and create the view in-place.</p>


<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">handler500</span><span class="p">(</span><span class="n">request</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="s">An error handler which exposes the request object to the error template.</span>
</span><span class='line'><span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">django.template</span> <span class="kn">import</span> <span class="n">Context</span><span class="p">,</span> <span class="n">loader</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">django.http</span> <span class="kn">import</span> <span class="n">HttpResponseServerError</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">disqus.context_processors</span> <span class="kn">import</span> <span class="n">default</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">logging</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'><span class="k">try</span><span class="p">:</span>
</span><span class='line'>    <span class="n">context</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
</span><span class='line'><span class="k">except</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span>
</span><span class='line'>    <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">(),</span> <span class="n">extra</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;request&#39;</span><span class="p">:</span> <span class="n">request</span><span class="p">})</span>
</span><span class='line'>    <span class="n">context</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'><span class="n">context</span><span class="p">[</span><span class="s">&#39;request&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">request</span>
</span><span class='line'>
</span><span class='line'><span class="n">t</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">get_template</span><span class="p">(</span><span class="s">&#39;500.html&#39;</span><span class="p">)</span> <span class="c"># You need to create a 500.html template.</span>
</span><span class='line'><span class="k">return</span> <span class="n">HttpResponseServerError</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">Context</span><span class="p">(</span><span class="n">context</span><span class="p">)))</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>We're going to expose the request object to our 500.html in the above. Keep in mind, that doing this allows you to add some logic into your template, and you're going to need to be very careful that this logic can't raise a new exception.</p>




<h5>Tweaking your 500.html</h5>




<p>The next thing you'll need to do is to tweak your 500.html template to actually show the Sentry ID. Assuming the request object was passed into Sentry, it will attach the last error seen under <code>request.sentry['id']</code>. Given this, we can easily report it to the end-user in our template:</p>




<pre>
&lt;p&gt;The Disqus team has been alerted and we're on the case. For more information, check out &lt;a href="http://status.disqus.com"&gt;Disqus Status &raquo;&lt;/a&gt;&lt;/p&gt;
&#123;% if request.sentry.id %&#125;
    &lt;p&gt;If you need assistance, you may reference this error as &lt;strong&gt;&#123;&#123; request.sentry.id &#125;&#125;&lt;/strong&gt;.&lt;/p&gt;
&#123;% endif %&#125;
</pre>




<h4>Sentry ID as a response header</h4>




<p>The other quick solution to get access to this variable is simply by enabling an included response middleware, <code>SentryResponseErrorIdMiddleware</code>. Just pop open your <code>settings.py</code> and append it to your <code>MIDDLEWARE_CLASSES</code>:</p>


<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">MIDDLEWARE_CLASSES</span> <span class="o">=</span> <span class="p">(</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;...</span><span class="p">,</span>
</span><span class='line'><span class="s">&#39;sentry.client.middleware.SentryResponseErrorIdMiddleware&#39;</span><span class="p">,</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Now if you check your response headers after hitting an error, you should see <code>X-Sentry-ID</code>.</p>




<h4>Find errors by ID</h4>




<p>Sentry makes it very easy to pull up error messages by ID. The one requirement is that you're going to need to ensure <code>sentry.filters.SearchFilter</code> is included within <code>SENTRY_FILTERS</code> (it's enabled by default). Once done, Sentry will discover if you're entering a UUID hex value (the Sentry ID) in the search box, and it will jump directly to that error's page.</p>




<p><img src="http://f.cl.ly/items/2f1s1X0J231F2F3u0V0d/sentry-id.png"/></p>




<p>You'll also notice that all messages are now tagged with their unique Sentry ID as well (per the screenshot).</p>

]]></content>
  </entry>
  
</feed>
